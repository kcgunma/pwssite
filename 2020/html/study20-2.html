<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">

<html lang="ja" dir="ltr">
<head>
  <meta name="generator" content=
  "HTML Tidy for Linux (vers 25 March 2009), see www.w3.org">
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8">
  <script src="jquery.min.js" type="text/javascript">
</script>

  <title>PWS2020</title>
  <link rel="stylesheet" type="text/css" href="./style.css">
</head>

<body style="margin-top:40px">
  <div id="menu-wrap" class="fixed">
    <ul id="menu">
      <li><a href="./index.html">Top</a></li>

      <li><a href="./index.html">About PWS</a></li>

      <li><a href="./cup20.html">PWSCUP 2020</a></li>

      <li><a href="http://www.iwsec.org/pws">Past PWS</a></li>
    </ul>
  </div>

  <div id="page">
    <!-- contents start -->

    <h1>第二回 PWS論文読破会</h1>

    <h2>What' new</h2>

    <ul>
      <li>2021/02/01(月) 本ページを作成</li>
    </ul>

    <h2>開催概要</h2>

    <p>
    プライバシーに関する論文は、様々な分野の国際会議に発表されており関連技術も多数存在するため、プライバシーに関する技術動向を追うことは容易では無いと感じています。そこで、プライバシ関係の研究の促進を目的として、トップカンファレンスで発表されているプライバシ関係の論文を簡単に紹介し合う「PWS論文読破会」を企画しました。前回の<a href="study20.html">第1回開催</a>に引き続き、第2回目を開催したいと思います。</p>

    <p>
    発表者・聴講者(特に、発表者)を募集しますので、下記の問い合わせ先にご連絡頂ければ幸いです。発表者の申し込みは、定員に達し次第締め切ります。</p>

    <p>論文は2020年8月～2021年1月に発表されたプライバシ (秘密計算、差分プライバシ、匿名化、Federated
    Learning等)を中心にご自由にお選びください。 また、プライバシと同様に注目されているデータ活用やAIにおける信頼性
    (Safety, Fairness. Accountabilityなど) に関する論文も歓迎します。
    ご参考までに、NeurIPS2020 CCS2020 VLDB2020 KDD2020
    からリストアップした論文リストを掲載します。(リストアップされていない論文も大歓迎です)</p>

    <h2>日時・場所</h2>

    <ul>
      <li>2021年3月24日(水) 15:00〜18:00(予定)
      ※終了後に希望者でオンライン飲み会もしたいと思います</li>

      <li>オンライン Zoom (発表者・聴講者に別途URL等をご連絡しますので、申し込みをお願いします)</li>

      <li>参加費無料</li>
    </ul>

    <h2>発表申込</h2>

    <p>発表を希望される方は、次のアドレスに電子メールをお送りください。</p>

    <p>　　tsubasa.takahashi あっとまーく linecorp.com</p>

    <p>ご記載いただきたい内容：</p>

    <ul>
      <li>氏名</li>

      <li>所属（会社名、学校名など）</li>

      <li>メールアドレス</li>

      <li>希望する論文</li>
    </ul>

    <p>
    最新動向を追う事を目的としているため、比較的広く浅く論文を読んで、紹介し合うことを想定しています。そのため、必ずしも深く論文を読み綺麗な資料を作成する必要は無く、発表者の負荷はなるべく小さくしたいと考えております。</p>

    <p>1論文につき10~15分程度（質疑込み）を想定しています。</p>

    <h2>聴講申込</h2>

    <p>聴講を希望される方は、<a href=
    "https://forms.gle/QQyd6Dc54fxpJvew5">申し込みフォーム</a>にメールアドレスなどを入力してください。後日、参加方法(Zoom
    URLなど)を連絡します。</p>

    <p>なお、入力頂いた内容は本イベントの運営のために利用します。プライバシポリシは<a href=
    "http://www.ipsj.or.jp/privacypolicy.html">こちら</a>を参照ください。</p>

    <h2>プログラム (暫定)</h2>

    <ul>
      <li>オープニング</li>

      <li>15:10-15:30</li>

      <li>15:30-15:50</li>

      <li>15:50-16:10</li>

      <li>16:10-16:30</li>

      <li>休憩</li>

      <li>16:45-17:05</li>

      <li>17:05-17:25</li>

      <li>17:25-17:45</li>

      <li>17:45-18:05</li>

      <li>クロージング</li>
    </ul>

    <h2>発表予定</h2>

    <ul>
      <li>渡辺知恵美 "ObliDB: Oblivious Query Processing for Secure
      Databases", VLDB20</li>

      <li>高橋翼 "Collecting and Analyzing Data Jointly from Multiple
      Services under Local Differential Privacy", VLDB20</li>

      <li>リュウセンペイ "Inverting Gradients - How easy is it to break
      privacy in federated learning?", NeurIPS20</li>

      <li>上野道彦 "Exploring Design and Governance Challenges in the
      Development of Privacy-Preserving Computation", CHI21</li>

      <li>竹之内隆夫 "未定"</li>
    </ul>

    <h2>代表的な国際会議論文リスト</h2>

    <h3>KDD2020</h3>

    <ul>
      <li>Estimating Properties of Social Networks via Random Walk
      considering Private Nodes</li>

      <li>Re-identification Attack to Privacy-Preserving Data
      Analysis with Noisy Sample-Mean</li>

      <li>TIPRDC: Task-Independent Privacy-Respecting Data
      Crowdsourcing Framework for Deep Learning with Anonymized
      Intermediate Representations</li>

      <li>Privileged Features Distillation at Taobao
      Recommendations</li>

      <li>Faster Secure Data Mining via Distributed Homomorphic
      Encryption</li>

      <li>Algorithmic Decision Making with Conditional
      Fairness</li>

      <li>Evaluating Fairness using Permutation Tests</li>

      <li>InFoRM: Individual Fairness on Graph Mining</li>

      <li>List-wise Fairness Criterion for Point Processes</li>

      <li>Towards Fair Truth Discovery from Biased Crowdsourced
      Answers</li>

      <li>Attackability Characterization of Adversarial Evasion
      Attack on Discrete Data</li>

      <li>Interpretability is a Kind of Safety: An
      Interpreter-based Ensemble for Adversary Defense</li>

      <li>RayS: A Ray Searching Method for Hard-label Adversarial
      Attack</li>

      <li>Vulnerability vs. Reliability: Disentangled Adversarial
      Examples for Cross-Modal Learning</li>

      <li>INPREM: An Interpretable and Trustworthy Predictive Model
      for Healthcare</li>
    </ul>

    <h3>VLDB2020</h3>

    <ul>
      <li>Collecting and Analyzing Data Jointly from Multiple
      Services under Local Differential Privacy</li>

      <li>Free Gap Information from the Differentially Private
      Sparse Vector and Noisy Max Mechanisms</li>

      <li>A workload-adaptive mechanism for linear queries under
      local differential privacy</li>

      <li>SAQE: Practical Privacy-Preserving Approximate Query
      Processing for Data Federations</li>

      <li>ObliDB: Oblivious Query Processing for Secure
      Databases</li>

      <li>Efficient Oblivious Database Joins</li>

      <li>Set-valued Data Publication with Local Privacy: Tight
      Error Bounds and Efficient Mechanisms</li>

      <li>Relational Data Synthesis using Generative Adversarial
      Networks: A Design Space Exploration</li>

      <li>Secure Multi-Party Functional Dependency Discovery</li>

      <li>TransNet: Training Privacy-Preserving Neural Network over
      Transformed Layer</li>

      <li>Privacy Preserving Vertical Federated Learning for
      Tree-based Models</li>

      <li>Efficient Confidentiality-Preserving Data Analytics over
      Symmetrically Encrypted Datasets</li>

      <li>Rank Aggregation Algorithms for Fair Consensus</li>

      <li>Fair Task Assignment in Spatial Crowdsourcing</li>

      <li>Sieve: A Middleware Approach to Scalable Access Control
      for Database Management Systems</li>

      <li>Understanding and Benchmarking the Impact of GDPR on
      Database Systems</li>

      <li>Operationalizing Individual Fairness with Pairwise Fair
      Representations</li>
    </ul>

    <h3>CCS2020</h3>

    <ul>
      <li>Private Summation in the Multi-Message Shuffle Model</li>

      <li>R^2DP: A Universal and Automated Approach to Optimizing
      the Randomization Mechanisms of Differential Privacy for
      Utility Metrics with No Known Optimal Distributions</li>

      <li>Privaros: A Framework for Privacy-Compliant Delivery
      Drones</li>

      <li>Implementing the Exponential Mechanism with Base-2
      Differential Privacy</li>

      <li>Usage Patterns of Privacy-Enhancing Technologies</li>

      <li>CheckDP: An Automated and Integrated Approach for Proving
      Differential Privacy or Finding Precise Counterexamples</li>

      <li>The Signal Private Group System and Anonymous Credentials
      Supporting Efficient Verifiable Encryption</li>

      <li>Dangerous Skills Got Certified: Measuring the
      Trustworthiness of Skill Certification in Voice Personal
      Assistant Platforms</li>

      <li>Threshold Password-Hardened Encryption Services</li>

      <li>CrypTFlow2: Practical 2-Party Secure Inference</li>
    </ul>

    <h3>NeurIPS2020</h3>

    <ul>
      <li>Adversarially Robust Streaming Algorithms via
      Differential Privacy</li>

      <li>Permute-and-Flip: A new mechanism for differentially
      private selection</li>

      <li>Learning from Mixtures of Private and Public
      Populations</li>

      <li>Locally private non-asymptotic testing of discrete
      distributions is faster using interactive mechanisms</li>

      <li>Optimal Private Median Estimation under Minimal
      Distributional Assumptions</li>

      <li>Breaking the Communication-Privacy-Accuracy Trilemma</li>

      <li>Differentially Private Clustering: Tight Approximation
      Ratios</li>

      <li>Privacy Amplification via Random Check-Ins</li>

      <li>Towards practical differentially private causal graph
      discovery</li>

      <li>Differentially-Private Federated Linear Bandits</li>

      <li>Synthetic Data Generators -- Sequential and Private</li>

      <li>Faster Differentially Private Samplers via Rényi
      Divergence Analysis of Discretized Langevin MCMC</li>

      <li>A Scalable Approach for Privacy-Preserving Collaborative
      Machine Learning</li>

      <li>AutoPrivacy: Automated Layer-wise Parameter Selection for
      Secure Neural Network Inference</li>

      <li>Smoothed Analysis of Online and Differentially Private
      Learning</li>

      <li>Private Identity Testing for High-Dimensional
      Distributions</li>

      <li>Locally Differentially Private (Contextual) Bandits
      Learning</li>

      <li>GS-WGAN: A Gradient-Sanitized Approach for Learning
      Differentially Private Generators</li>

      <li>Understanding Gradient Clipping in Private SGD: A
      Geometric Perspective</li>

      <li>Private Learning of Halfspaces: Simplifying the
      Construction and Reducing the Sample Complexity</li>

      <li>Smoothly Bounding User Contributions in Differential
      Privacy</li>

      <li>Instance-optimality in differential privacy via
      approximate inverse sensitivity mechanisms</li>

      <li>CoinPress: Practical Private Mean and Covariance
      Estimation</li>

      <li>The Discrete Gaussian for Differential Privacy</li>

      <li>On the Equivalence between Online and Private
      Learnability beyond Binary Classification</li>

      <li>Inverting Gradients - How easy is it to break privacy in
      federated learning?</li>

      <li>CryptoNAS: Private Inference on a ReLU Budget</li>

      <li>The Flajolet-Martin Sketch Itself Preserves Differential
      Privacy: Private Counting with Minimal Space</li>

      <li>Improving Sparse Vector Technique with Renyi Differential
      Privacy</li>

      <li>A Computational Separation between Private Learning and
      Online Learning</li>

      <li>Learning discrete distributions: user vs item-level
      privacy</li>

      <li>Auditing Differentially Private Machine Learning: How
      Private is Private SGD?</li>

      <li>Fairness without Demographics through Adversarially
      Reweighted Learning</li>

      <li>Fairness with Overlapping Groups; a Probabilistic
      Perspective</li>

      <li>Robust Optimization for Fairness with Noisy Protected
      Groups</li>

      <li>Fair regression with Wasserstein barycenters</li>

      <li>Learning Certified Individually Fair Representations</li>

      <li>Fair Performance Metric Elicitation</li>

      <li>Metric-Free Individual Fairness in Online Learning</li>

      <li>Fairness constraints can help exact inference in
      structured prediction</li>

      <li>Probabilistic Fair Clustering</li>

      <li>Fairness in Streaming Submodular Maximization: Algorithms
      and Hardness</li>

      <li>Group-Fair Online Allocation in Continuous Time</li>

      <li>KFC: A Scalable Approximation Algorithm for k−center Fair
      Clustering</li>

      <li>A Fair Classifier Using Kernel Density Estimation</li>

      <li>Exploiting MMD and Sinkhorn Divergences for Fair and
      Transferable Representation Learning</li>

      <li>Fair Multiple Decision Making Through Soft
      Interventions</li>

      <li>Ensuring Fairness Beyond the Training Data</li>

      <li>How do fair decisions fare in long-term
      qualification?</li>

      <li>Can I Trust My Fairness Metric? Assessing Fairness with
      Unlabeled Data and Bayesian Inference</li>

      <li>Fair regression via plug-in estimator and recalibration
      with statistical guarantees</li>

      <li>Fair Hierarchical Clustering</li>

      <li>Falcon: Fast Spectral Inference on Encrypted Data</li>

      <li>Glyph: Fast and Accurately Training Deep Neural Networks
      on Encrypted Data</li>

      <li>Optimal Query Complexity of Secure Stochastic Convex
      Optimization</li>
    </ul>

    <h2>お問い合わせ先</h2>

    <ul>
      <li>竹之内: takao-takenouchi あっとまーく garage.co.jp</li>

      <li>高橋: tsubasa.takahashi　あっとまーく linecorp.com</li>
    </ul><!-- contents end -->
  </div><script type="text/javascript">
      $(function(){
          var box    = $("#menu-wrap");
          var boxTop = box.offset().top;
          $(window).scroll(function () {
            if($(window).scrollTop() >= boxTop) {
              box.addClass("fixed");
              $("body").css("margin-top","40px");
            } else {
              box.removeClass("fixed");
              $("body").css("margin-top","0px");
           }
          });
        });
  </script>
</body>
</html>
