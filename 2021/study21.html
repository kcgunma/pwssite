<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">

<html lang="ja" dir="ltr">
<head>
  <meta name="generator" content=
  "HTML Tidy for Linux (vers 25 March 2009), see www.w3.org">
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8">
  <script src="jquery.min.js" type="text/javascript">
</script>

  <title>PWS2021</title>
  <link rel="stylesheet" type="text/css" href="./style.css">
</head>

<body style="margin-top:40px">
  <div id="menu-wrap" class="fixed">
    <ul id="menu">
      <li><a href="./index.html">Top</a></li>

      <li><a href="./index.html">About PWS</a></li>

      <li><a href="./cup20.html">PWSCUP 2020</a></li>

      <li><a href="http://www.iwsec.org/pws">Past PWS</a></li>
    </ul>
  </div>

  <div id="page">
    <!-- contents start -->

    <h1>第三回 PWS論文読破会</h1>

    <h2>What' new</h2>

    <ul>
      <li>2021/04/27(火) 本ページを作成</li>

      <li>2021/05/11(火) 参考論文リストを記載</li>
    </ul>

    <h2>開催概要</h2>

    <p>
    プライバシーに関する論文は、様々な分野の国際会議に発表されており関連技術も多数存在するため、プライバシーに関する技術動向を追うことは容易では無いと感じています。そこで、プライバシ関係の研究の促進を目的として、トップカンファレンスで発表されているプライバシ関係の論文を簡単に紹介し合う「PWS論文読破会」を企画しました。<a href="../2020/study20.html">第1回開催</a>、<a href="../2020/study20-2.html">第2回開催</a>に引き続き、第3回目を開催したいと思います。</p>

    <p>
    発表者・聴講者(特に、発表者)を募集しますので、下記の問い合わせ先にご連絡頂ければ幸いです。発表者の申し込みは、定員に達し次第締め切ります。</p>

    <p>論文は2021年1月～2021年5月に発表されたプライバシ (秘密計算、差分プライバシ、匿名化、Federated
    Learning等) を中心にご自由にお選びください。 また、プライバシと同様に注目されているデータ活用やAIにおける信頼性
    (Safety, Fairness. Accountabilityなど) に関する論文も歓迎します。
    ご参考までに、S&amp;P, NDSS, ICLR, AIStats, ICDE
    からリストアップした論文リストを掲載します。(リストアップされていない論文も大歓迎です)</p>

    <h2>日時・場所</h2>

    <ul>
      <li>2021年6月16日(水) 15:00〜18:00(予定)
      ※終了後に希望者でオンライン飲み会もしたいと思います</li>

      <li>オンライン Zoom (発表者・聴講者に別途URL等をご連絡しますので、申し込みをお願いします)</li>

      <li>参加費無料</li>
    </ul>

    <h2>発表申込</h2>

    <p>発表を希望される方は、次のアドレスに電子メールをお送りください。</p>

    <p>　　tsubasa.takahashi あっとまーく linecorp.com</p>

    <p>ご記載いただきたい内容：</p>

    <ul>
      <li>氏名</li>

      <li>所属（会社名、学校名など）</li>

      <li>メールアドレス</li>

      <li>希望する論文</li>
    </ul>

    <p>
    最新動向を追う事を目的としているため、比較的広く浅く論文を読んで、紹介し合うことを想定しています。そのため、必ずしも深く論文を読み綺麗な資料を作成する必要は無く、発表者の負荷はなるべく小さくしたいと考えております。</p>

    <p>1論文につき10~15分程度（質疑込み）を想定しています。</p>

    <h2>聴講申込</h2>

    <p>聴講を希望される方は、<a href=
    "https://forms.gle/57T9kEDsW5ujjmXw6">申し込みフォーム</a>にメールアドレスなどを入力してください。後日、参加方法(Zoom
    URLなど)を連絡します。</p>

    <p>なお、入力頂いた内容は本イベントの運営のために利用します。プライバシポリシは<a href=
    "http://www.ipsj.or.jp/privacypolicy.html">こちら</a>を参照ください。</p>

    <h2>プログラム</h2>

    <ul>
      <li>15:00-15:05 オープニング</li>

      <li>15:05-15:20 発表1</li>

      <li>15:20-15:35 発表2</li>

      <li>15:35-15:50 発表3</li>

      <li>15:50-16:00 休憩</li>

      <li>16:00-16:15 発表4</li>

      <li>16:15-16:30 発表5</li>

      <li>16:30-16:45 発表6</li>

      <li>16:45-17:00 休憩</li>

      <li>17:00-17:15 発表7</li>

      <li>17:15-17:30 発表8</li>

      <li>17:30-17:45 発表9</li>

      <li>クロージング</li>
    </ul>

    <h2>代表的な国際会議論文リスト</h2>

    <h3>IEEE S&amp;P 2021</h3>

    <ul>
      <li>Detecting AI Trojans Using Meta Neural Analysis</li>

      <li>Adversarial Watermarking Transformer: Towards Tracing
      Text Provenance with Data Hiding</li>

      <li>Machine Unlearning</li>

      <li>Defensive Technology Use by Political Activists During
      the Sudanese Revolution</li>

      <li>DP-Sniper: Black-Box Discovery of Differential Privacy
      Violations using Classifiers</li>

      <li>Is Private Learning Possible with Instance Encoding?</li>

      <li>DIANE: Identifying Fuzzing Triggers in Apps to Generate
      Under-constrained Inputs for IoT Devices</li>

      <li>Data Privacy in Trigger-Action Systems</li>

      <li>Which Privacy and Security Attributes Most Impact
      Consumers‚ Risk Perception and Willingness to Purchase IoT
      Devices?</li>

      <li>Learning Differentially Private Mechanisms</li>

      <li>Adversary Instantiation: Lower bounds for differentially
      private machine learning</li>

      <li>Manipulation Attacks in Local Differential Privacy</li>

      <li>SIRNN: A Math Library for Secure RNN Inference</li>

      <li>CryptGPU: Fast Privacy-Preserving Machine Learning on the
      GPU</li>

      <li>Proof-of-Learning: Definitions and Practice</li>

      <li>Pegasus: Bridging Polynomial and Non-polynomial
      Evaluations in Homomorphic Encryption</li>

      <li>Wolverine: Fast, Scalable, and Communication-Efficient
      Zero-Knowledge Proofs for Boolean and Arithmetic
      Circuits</li>

      <li>SoK: Fully Homomorphic Encryption Compilers</li>
    </ul>

    <h3>NDSS 2021</h3>

    <ul>
      <li>GALA: Greedy ComputAtion for Linear Algebra in
      Privacy-Preserved Neural Networks</li>

      <li>POSEIDON: Privacy-Preserving Federated Neural Network
      Learning</li>

      <li>PrivacyFlash Pro: Automating Privacy Policy Generation
      for Mobile Apps</li>

      <li>Understanding Worldwide Private Information Collection on
      Android</li>

      <li>FLTrust: Byzantine-robust Federated Learning via Trust
      Bootstrapping</li>

      <li>Manipulating the Byzantine: Optimizing Model Poisoning
      Attacks and Defenses for Federated Learning</li>
    </ul>

    <h3>ICDE 2021</h3>

    <ul>
      <li>Differentially Private Publication of Multi-Party
      Sequential Data</li>

      <li>Secure Dynamic Skyline Queries Using Result
      Materialization</li>

      <li>P3GM: Private High-Dimensional Data Release via Privacy
      Preserving Phased Generative Model</li>

      <li>Feature Inference Attack on Model Predictions in Vertical
      Federated Learning</li>

      <li>Privacy Preserving Strong Simulation Queries for Large
      Graphs</li>

      <li>Aria: Tolerating Skewed Workloads in Secure In-memory
      Key-Value Store</li>

      <li>Efficient Federated-Learning Model Debugging</li>

      <li>An Efficient Approach for Cross-Silo Federated Learning
      to Rank</li>
    </ul>

    <h3>AIStats 2021</h3>

    <ul>
      <li>Revisiting Model-Agnostic Private Learning: Faster Rates
      and Active Learning</li>

      <li>Differentially Private Analysis on Graph Streams</li>

      <li>Differentially Private Online Submodular
      Maximization</li>

      <li>On the Privacy Properties of GAN-generated Samples</li>

      <li>Robust and Private Learning of Halfspaces</li>

      <li>DP-MERF: Differentially Private Mean Embeddings with
      RandomFeatures for Practical Privacy-preserving Data
      Generation</li>

      <li>Stability and Differential Privacy of Stochastic Gradient
      Descent for Pairwise Learning with Non-Smooth Loss</li>

      <li>No-Regret Algorithms for Private Gaussian Process Bandit
      Optimization</li>

      <li>Federated f-Differential Privacy</li>

      <li>Quantifying the Privacy Risks of Learning
      High-Dimensional Graphical Models</li>

      <li>Optimal query complexity for private sequential learning
      against eavesdropping</li>

      <li>Differentially Private Weighted Sampling</li>

      <li>Shuffled Model of Differential Privacy in Federated
      Learning</li>

      <li>Private optimization without constraint violations</li>

      <li>Evading the Curse of Dimensionality in Unconstrained
      Private GLMs</li>

      <li>Location Trace Privacy Under Conditional Priors</li>

      <li>Differentially Private Monotone Submodular Maximization
      Under Matroid and Knapsack Constraints</li>

      <li>Tight Differential Privacy for Discrete-Valued Mechanisms
      and for the Subsampled Gaussian Mechanism Using FFT</li>

      <li>On Data Efficiency of Meta-learning for Personalized
      Federated Learning</li>

      <li>Free-rider Attacks on Model Aggregation in Federated
      Learning</li>

      <li>Federated Learning with Compression: Unified Analysis and
      Sharp Guarantees</li>

      <li>Convergence and Accuracy Trade-Offs in Federated Learning
      and Meta-Learning</li>

      <li>Federated Multi-armed Bandits with Personalization</li>

      <li>Towards Flexible Device Participation in Federated
      Learning</li>

      <li>Learning Individually Fair Classifier with Path-Specific
      Causal-Effect Constraint</li>

      <li>Learning Smooth and Fair Representations</li>

      <li>Learning Fair Scoring Functions: Bipartite Ranking under
      ROC-based Fairness Constraints</li>

      <li>Algorithms for Fairness in Sequential Decision
      Making</li>

      <li>All of the Fairness for Edge Prediction with Optimal
      Transport</li>

      <li>Fair for All: Best-effort Fairness Guarantees for
      Classification</li>
    </ul>

    <h3>ICLR 2021</h3>

    <ul>
      <li>Bypassing the Ambient Dimension: Private SGD with
      Gradient Subspace Identification</li>

      <li>Information Laundering for Model Privacy</li>

      <li>Differentially Private Learning Needs Better Features (or
      Much More Data)</li>

      <li>Do not Let Privacy Overbill Utility: Gradient Embedding
      Perturbation for Private Learning</li>

      <li>Private Image Reconstruction from System Side Channels
      Using Generative Models</li>

      <li>R-GAP: Recursive Gradient Attack on Privacy</li>

      <li>CaPC Learning: Confidential and Private Collaborative
      Learning</li>

      <li>Private Post-GAN Boosting</li>

      <li>SenSeI: Sensitive Set Invariance for Enforcing Individual
      Fairness</li>

      <li>Fair Mixup: Fairness via Interpolation</li>

      <li>FairBatch: Batch Selection for Model Fairness</li>

      <li>Statistical inference for individual fairness</li>

      <li>Individually Fair Rankings</li>

      <li>Individually Fair Gradient Boosting</li>

      <li>FairFil: Contrastive Neural Debiasing Method for
      Pretrained Text Encoders</li>

      <li>On Dyadic Fairness: Exploring and Mitigating Bias in
      Graph Connections</li>

      <li>Personalized Federated Learning with First Order Model
      Optimization</li>

      <li>FedMix: Approximation of Mixup under Mean Augmented
      Federated Learning</li>

      <li>Federated Semi-Supervised Learning with Inter-Client
      Consistency &amp; Disjoint Learning</li>

      <li>Achieving Linear Speedup with Partial Worker
      Participation in Non-IID Federated Learning</li>

      <li>FedBE: Making Bayesian Model Ensemble Applicable to
      Federated Learning</li>

      <li>Federated Learning via Posterior Averaging: A New
      Perspective and Practical Algorithms</li>

      <li>HeteroFL: Computation and Communication Efficient
      Federated Learning for Heterogeneous Clients</li>

      <li>FedBN: Federated Learning on Non-IID Features via Local
      Batch Normalization</li>

      <li>SAFENet: A Secure, Accurate and Fast Neural Network
      Inference</li>
    </ul>

    <h2>お問い合わせ先</h2>

    <ul>
      <li>竹之内: takao-takenouchi あっとまーく garage.co.jp</li>

      <li>高橋: tsubasa.takahashi　あっとまーく linecorp.com</li>
    </ul><!-- contents end -->
  </div><script type="text/javascript">
      $(function(){
          var box    = $("#menu-wrap");
          var boxTop = box.offset().top;
          $(window).scroll(function () {
            if($(window).scrollTop() >= boxTop) {
              box.addClass("fixed");
              $("body").css("margin-top","40px");
            } else {
              box.removeClass("fixed");
              $("body").css("margin-top","0px");
           }
          });
        });
  </script>
</body>
</html>
